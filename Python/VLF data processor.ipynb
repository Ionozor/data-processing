{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VLF data processor\n",
    "## VojtÄ›ch Laitl 2016\n",
    "### Ionozor Measuring Network - VLF monitors data anylysis and graph processing\n",
    "\n",
    "This is an iPython Juypter notebook made for SID monitors and periodical viewing of the processed VLF data. The computations are covered by a simplified ionospheric plasma physics model and based on iPython 2.X modules. The script does not save any pictures, nor data given. The supporting files are deleted when the calculations and plotting are finished, so the notebook works only with the primary data measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bzpost\n",
    "import datetime, requests, os, glob\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy\n",
    "import astropy.io \n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import quad\n",
    "import cmath\n",
    "import scipy.interpolate as interpol\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the libraries needed for the script are defined and imported. The notebook works with the bzpost module (https://github.com/bolidozor/python-bolidozor-postprocessing/tree/master) installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourceUrl = 'http://space.astro.cz/ionozor/VLF/svakov/SVAKOV_VLF_R0/'\n",
    "\n",
    "year_start = np.asarray(time.gmtime()[0],dtype='int')\n",
    "year_end = year_start\n",
    "month_start = np.asarray(str(time.gmtime()[1]).zfill(2),dtype='int')\n",
    "month_end = month_start\n",
    "day_start = np.asarray(str(time.gmtime()[2]).zfill(2),dtype='int')\n",
    "hour_start = np.asarray(str(time.gmtime()[3]).zfill(2),dtype='int')\n",
    "\n",
    "if hour_start<0:\n",
    "\tday_start = day_start-1\n",
    "\thour_start = 23\n",
    "\n",
    "day_end = day_start\n",
    "hour_end = hour_start\n",
    "minute_start = np.asarray(str(1).zfill(2),dtype='int')\n",
    "minute_end = np.asarray(str(59).zfill(2),dtype='int')\n",
    "\n",
    "print('The initial time is given by:')\n",
    "print(year_start,month_start,day_start,hour_start,minute_start)\n",
    "print('The terminal time is given by:')\n",
    "print(year_end,month_end,day_end,hour_end,minute_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the modules are downloaded, the first step of the computation is given, so the time of the hour passed is defined for downloading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    local_filename = url.split('/')\n",
    "    # note the stream=True parameter\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open('local_filename', 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "                f.flush()\n",
    "    return local_filename\n",
    "\n",
    "print('The souce URL is:')\t\n",
    "print(sourceUrl)\n",
    "download_file(sourceUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data downloading is solved, called by a print output and set up to be run. The source URL is defined above within the datetime parameters and being set for each observatory and station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_fits(dir, year_start, month_start, day_start, hour_start, minute_start, year_end, month_end, day_end, hour_end, minute_end):\n",
    "    '''\n",
    "    Creates subdirectory 'snapshots' and downloads set of fits images from http://space.astro.cz/bolidozor/ from time period given in arguments. Returns nothing.\n",
    "    >>>import getboli\n",
    "    >>>getboli.download_fits('snapshots',2015,8,8,4,1,2015,8,9,6,1)\n",
    "    >>>\n",
    "    '''\n",
    "    collector = []\n",
    "    wd = os.getcwd()\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    os.chdir(dir)\n",
    "    con = bzpost.HTTPConnector(sourceUrl)\n",
    "    con.connect()\n",
    "\n",
    "    for snapshot in con.get_snapshots(datetime.datetime(year_start, month_start, day_start, hour_start, minute_start), datetime.datetime(year_end, month_end, day_end, hour_end, minute_end)):\n",
    "       collector.append(snapshot.url) \n",
    "\n",
    "    for url in collector:\n",
    "        download_file(url)\n",
    "\n",
    "    con.close()\n",
    "    os.chdir(wd)\n",
    "\t\n",
    "download_fits('snapshots', year_start, month_start, day_start, hour_start, minute_start, year_end, month_end, day_end, hour_end, minute_end)\n",
    "print('The directory and datetime are given by:')\n",
    "print('snapshots', year_start, month_start, day_start, hour_start, minute_start, year_end, month_end, day_end, hour_end, minute_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the datetime functions are set into a tool which covers the parameters of data downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkmosaic(dir, output='out.fits', axis='y', part=1, showplot=True):\n",
    "    '''\n",
    "    Concaternate specified parts of images from directory along the geometric axis. Plots the output by default. Having something else than fits files in target directory will likely result in error.\n",
    "    :dir: The directory in which fits images are situated.\n",
    "    :output: The filename of the output concaternated image.\n",
    "    :axis: The axis in cartesian coordinate system along which the pictures are added.\n",
    "    :part: What part of the fits images should be added. Default fits images have header on 0 and image part on 1. Raw files have each channel on 0, 1, 2 without a header.\n",
    "    :showplot: If set to True the output is drawn using matplotlib.\n",
    "    :return: Nothing.\n",
    "    >>>import getboli\n",
    "    >>>getboli.mkmosaic('snapshots', 'out.fits', axis='x', part='0')\n",
    "    >>>\n",
    "    TODO: .*\\.fits regex\n",
    "    '''\n",
    "    for image in os.listdir(dir):\n",
    "        hdulist = fits.open(os.path.join(dir, image))\n",
    "        if 'a' in locals():\n",
    "            if axis == 'x':\n",
    "                a = np.append(a, hdulist[part].data, axis=1)\n",
    "            if axis == 'y':\n",
    "                a = np.append(a, hdulist[part].data, axis=0)\n",
    "            if axis == 'z':\n",
    "                a = np.add(a, hdulist[part].data)\n",
    "        else:\n",
    "            a = hdulist[part].data #matrix representing the image part\n",
    "        hdulist.close()\n",
    "    hdu = fits.PrimaryHDU(a)\n",
    "    hdu.writeto(output)\n",
    "    if showplot:\n",
    "        plt.imshow(a)\n",
    "        plt.show()\n",
    "    del a #when axis were switched the variable caused skip of the else condition\n",
    "\n",
    "mkmosaic('snapshots', 'out.fits', 'y', 1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely, the data are downloaded from the station's website and saved into the file of out.fits. Because of the next steps, no plot is drawn right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_list = fits.open('out.fits')\n",
    "data_list.info()\n",
    "data = data_list[0].data\n",
    "data_list.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data downloaded have just been written into a 2-D numpy array and are stored witihin the data chain since this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 8.8542e-12\n",
    "e = 1.602e-19\n",
    "k_B = 1.38e-23\n",
    "gamma = 0.001\n",
    "R_inf = 3.2899e15\n",
    "c = 3e8\n",
    "b = 2.898e-3\n",
    "h = 6.626e-34\n",
    "m_el = 9.109e-31\n",
    "R = 8.314\n",
    "N_A = 6.022e23\n",
    "lambda_De = 3.10399215e-05\n",
    "I0 = -26.74\n",
    "R = 1.496e11\n",
    "i = scipy.sqrt(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, all of the constants used for the oncoming calculations are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nu = 18000+(16+2/3)*np.arange(0,len(data))\n",
    "t = np.arange(0,len(data[0]))*3600/len(data[0])\n",
    "L = -data*1000\n",
    "n0 = -1/4*L**-4\n",
    "n0[np.isinf(n0)]=0\n",
    "E_k = -36*np.pi**-2*epsilon**-4/3*n0*e**4\n",
    "T = -E_k/k_B\n",
    "d_lambda_De = np.sqrt(np.abs((epsilon*k_B*T)/(n0*e**2)))\n",
    "p = np.diff(E_k,0)\n",
    "nu_delta = p*c/h\n",
    "omega = (nu+nu_delta.reshape((len(nu_delta[0]),len(nu)))).reshape((len(nu_delta),len(nu_delta[0])))\n",
    "n = (omega**2*m_el*epsilon)/e**2\n",
    "T_el = np.abs(T*n)\n",
    "T_el = T_el+190.05\n",
    "T_el[T_el>=10**4]=0\n",
    "n[n>9.99999*10**8]=0\n",
    "n = (n.reshape((len(nu_delta[0]),len(nu)))+(nu**2*m_el*epsilon)/e**2).reshape((len(nu_delta),len(nu_delta[0])))\n",
    "dn = np.diff(n,0)\n",
    "N_D = 4/3*np.pi*lambda_De*n\n",
    "N = (n.reshape((len(nu_delta[0]),len(nu)))-(nu**2*m_el*epsilon)/e**2).reshape((len(nu_delta),len(nu_delta[0])))\n",
    "Bl = 1+(0.01*L)\n",
    "mD = 10e-10\n",
    "h0 = np.pi*Bl/(2+2*mD)\n",
    "h0_t = (10*h0)**2/10\n",
    "f_n = dn*Bl/(N*(1-mD))\n",
    "f_n2 = f_n**2\n",
    "f_ln = np.log(1/2*f_n-((f_n2**2 - 4)**1/2))\n",
    "h_t = np.abs((Bl*f_ln + 2*np.pi*i)/(1-mD))\n",
    "H = np.nan_to_num(10*(h0_t + h_t)/3)\n",
    "H[H<59.999]=0\n",
    "Is = np.exp(L/10)\n",
    "fce = Is*R**2/I0\n",
    "alpha = scipy.arccos(fce)\n",
    "s = H*np.tan(np.abs(alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the time the data are downloaded and the mathematical constants are set, the equations involved in the simplified model are run. The cover the basic plasma parameters and the ionospheric drift characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_mean = np.mean(n,axis=1)\n",
    "T_mean = np.mean(T_el,axis=1)\n",
    "H_mean = np.mean(H,axis=1)*3\n",
    "s_mean = np.mean(s,axis=1)*3\n",
    "data_mean = np.mean(data,axis=1)\n",
    "L_mean = np.mean(L,axis=1)\n",
    "f = interpol.interp1d(nu,H_mean,kind='quadratic')\n",
    "F = f(nu)\n",
    "g = interpol.interp2d(nu,data_mean,L_mean)\n",
    "G = g(nu,data_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, the data output is simplified from the 2-D array into a single-axis chain containing the data used for the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.imshow(data)\n",
    "plt.colorbar()\n",
    "plt.title('Spectrograph')\n",
    "plt.xlabel('Time index')\n",
    "plt.ylabel('Frequency index')\n",
    "fig2 = plt.figure()\n",
    "ax = fig2.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(nu,data_mean,G)\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('L (dB)')\n",
    "ax.set_zlabel('dn/dL (1/m3)')\n",
    "ax.set_title('Plasma discharges')\n",
    "fig3 = plt.figure()\n",
    "plt.plot(nu,H_mean,'go'),plt.plot(nu,F)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Height (km)')\n",
    "plt.title('Ionogram')\n",
    "fig4 = plt.figure()\n",
    "plt.plot(n_mean,T_mean,'go')\n",
    "plt.xlabel('Electron density (1/m3)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.title('Charged particles')\n",
    "fig5 = plt.figure()\n",
    "plt.plot(H_mean,s_mean,'go')\n",
    "plt.xlabel('Vertical drift (km)')\n",
    "plt.ylabel('Horizontal drift (km)')\n",
    "plt.title('Ionospheric drift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the simplified data output is drawn using simple figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the final result, the figures drawn are shown using matplotlib.\n",
    "#### Spectrograph\n",
    "    The spectrograph plot shows the measured data themselves. The radio signal intensity level is shown within a 2-D char where the x-axis shows the time index and the y-axis the frequency index of the relative intensity of radio waves monitored.\n",
    "#### Plasma discharges\n",
    "    Plasma discharges plot covers the inital step of the mathematical model. The frequency set and the relative intensity measured are compared with each other and interlanded with the basic equation of the plasma physics model \n",
    "\\begin{equation}\n",
    "\\frac{\\partial{n}}{\\partial{L}} \\approx - \\frac{1}{4}L^{-4}\n",
    "\\end{equation}\n",
    "#### Ionogram\n",
    "    The next graph is the standard ionogram, a digram which shows the relation between the frequency (electron plasma frequency and thus mean electron density, respectively) and the height where the ionospheric plasma is being located. The ionogram involves both measured daa ad interpolaton.\n",
    "#### Charged particles\n",
    "    As the result of plasma paramters modelling, a simple diagram showing the electron density and plasma temperature is given.\n",
    "#### Ionospheric drift\n",
    "    The last step of this data processing tool is the diagram which shows the ionospheric plasma distribution involving both vertical distribution and horizontal distribution; they both are able to be reached within the ionogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.remove('out.fits')\n",
    "os.remove('local_filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having satisfied the data processing, the temporary supporting files containing the data measured are deleted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
